{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7344b34c",
   "metadata": {},
   "source": [
    "# Logbuch Analyzer\n",
    "## CAS Data Science - Text Analysis Projekt\n",
    "\n",
    "Kompakte Demonstration eines intelligenten Logbuch-Analyzers für Industriedaten.\n",
    "\n",
    "Dieses Notebook nutzt ausgelagerte Module für:\n",
    "- Robuste CSV-Verarbeitung mit automatischer Formaterkennung\n",
    "- Semantische Embeddings mit multilingualen E5-Modellen  \n",
    "- FAISS-optimierte Ähnlichkeitssuche\n",
    "- KI-gestützte Analyse mit Ollama LLM\n",
    "- Umfassende Evaluierung ohne Ground Truth\n",
    "\n",
    "Autor: [Ihr Name]\n",
    "Modul: CAS Data Science - Text Analysis\n",
    "Datum: Juni 2025\n",
    "\n",
    "Dateistruktur:\n",
    "- logbook_analyzer.py: Kernfunktionalität (LogbookAnalyzer-Klasse)\n",
    "- evaluation.py: Evaluierungsmodul (Ground Truth, Metriken)\n",
    "- utils.py: Hilfsfunktionen (Visualisierung, Export, Interaktion)\n",
    "- Logbuch_Spritzgussanlage_NEU.csv: Echte Industriedaten\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "85ff81f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGBUCH ANALYZER - CAS DATA SCIENCE PROJEKT\n",
      "============================================================\n",
      "Semantische Suche und KI-Analyse für Industriedaten\n",
      "Vollständig modularisierte Implementierung\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# IMPORTS UND KONFIGURATION\n",
    "# =============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Eigene Module\n",
    "from logbook_analyzer import load_and_setup_analyzer, get_data_statistics\n",
    "from evaluation import LogbookEvaluator\n",
    "\n",
    "# Standard Utils\n",
    "from utils import (\n",
    "    create_evaluation_visualizations, \n",
    "    interactive_query_demo,\n",
    "    print_system_summary,\n",
    "    create_demo_queries\n",
    ")\n",
    "\n",
    "# Pandas Darstellung optimieren\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "print(\"LOGBUCH ANALYZER - CAS DATA SCIENCE PROJEKT\")\n",
    "print(\"=\" * 60)\n",
    "print(\"Semantische Suche und KI-Analyse für Industriedaten\")\n",
    "print(\"Vollständig modularisierte Implementierung\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "325e13d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-15 14:22:05,543 - INFO - LogbookAnalyzer initialisiert mit Modell: intfloat/multilingual-e5-small\n",
      "2025-06-15 14:22:05,544 - INFO - Lade Embedding-Modell: intfloat/multilingual-e5-small\n",
      "2025-06-15 14:22:05,547 - INFO - Load pretrained SentenceTransformer: intfloat/multilingual-e5-small\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. SYSTEM INITIALISIERUNG\n",
      "----------------------------------------\n",
      "Lade und konfiguriere Logbook Analyzer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-15 14:22:08,600 - INFO - Erfolgreich geladen: intfloat/multilingual-e5-small\n",
      "2025-06-15 14:22:09,544 - INFO - Erkannt: ISO-8859-1 / Trennzeichen: ';'\n",
      "2025-06-15 14:22:09,550 - INFO - CSV geladen: 2500 Zeilen, 6 Spalten\n",
      "2025-06-15 14:22:09,557 - INFO - Datenverarbeitung abgeschlossen: 2500 gültige Einträge\n",
      "2025-06-15 14:22:09,558 - INFO - Erstelle semantische Embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d89a00d9cc364c68957806555bb4ad21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-15 14:22:20,914 - INFO - Embeddings erstellt: 2500 Einträge, 384 Dimensionen\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzer erfolgreich konfiguriert:\n",
      "  - Dateneinträge: 2500\n",
      "  - Embedding-Modell: intfloat/multilingual-e5-small\n",
      "  - Bereit für Analyse\n",
      "SYSTEM ERFOLGREICH INITIALISIERT\n",
      "- Dateneinträge: 2500\n",
      "- Embedding-Modell: intfloat/multilingual-e5-small\n",
      "\n",
      "2. DATENANALYSE FÜR VERBESSERTE GROUND TRUTH\n",
      "--------------------------------------------------\n",
      "Analyseergebnisse zur Produktionsproblematik:\n",
      "==================================================\n",
      "Query: Analysiere die kritischsten Probleme in der Produktion und identifiziere wiederkehrende Muster und Hauptursachen\n",
      "Gefundene relevante Einträge: 20 von 2500\n",
      "Durchschnittliche Relevanz: 0.831\n",
      "Maximale Relevanz: 0.834\n",
      "Suchqualität: Hoch\n",
      "\n",
      "LLM-Analyse (Zusammenfassung):\n",
      "**Direkte Antwort**\n",
      "\n",
      "Die kritischsten Probleme in der Produktion betreffen die Musterung von Serien, da in den meisten Einträgen das Ereignis \"Musterung: Spezialteam Process Engineering prüft, Serie noch nicht freigegeben\" auftritt. Dieses Problem ist besonders kritisch, da es wiederholt auftaucht und möglicherweise die Produktion verzögert oder behindert.\n",
      "\n",
      "**Relevante Einträge**\n",
      "\n",
      "Eintrag 1: Musterung: Spezialteam Process Engineering prüft, Serie noch nicht freigegeben (Lot-Nr.: 30983291)\n",
      "Eintrag 3: Musterung: Spezialteam Process Engineering prüft, Serie noch nicht freigegeben (Lot-Nr.: 30983346)\n",
      "Eintrag 9: Musterung: Spezialteam Process Engineering prüft, Serie noch nicht freigegeben (Lot-Nr.: 30983346)\n",
      "Eintrag 25: Musterung: Spezialteam Process Engineering prüft, Serie noch nicht freigegeben (Lot-Nr.: 30983346)\n",
      "\n",
      "**Zusammenfassung**\n",
      "\n",
      "Die Analyse der Logdaten zeigt, dass die kritischsten Probleme in der Produktion mit der Musterung von Serien zusammenhängen. Die wiederkehrenden Einträge deuten darauf hin, dass das Spezialteam Process Engineering Schwierigkeiten hat, die Serien zu prüfen und freizugeben. Dies könnte auf eine unzureichende Prozessoptimierung oder ein mangelhaftes Kommunikationsnetzwerk zwischen den Abteilungen hindeuten.\n",
      "\n",
      "**Empfehlungen**\n",
      "\n",
      "1. **Prozessoptimierung**: Es ist ratsam, die Prozesse für die Musterung von Serien zu überprüfen und zu optimieren, um die Produktionszeit zu verkürzen.\n",
      "2. **Kommunikationsnetzwerk**: Ein verbessertes Kommunikationsnetzwerk zwischen den Abteilungen könnte helfen, die Probleme bei der Musterung von Serien zu lösen.\n",
      "3. **Qualitätssicherung**: Es ist wichtig, die Qualität der produzierten Artikel zu überprüfen und zu sichern, um sicherzustellen, dass sie den Anforderungen entsprechen.\n",
      "\n",
      "Es ist ratsam, diese Empfehlungen umzusetzen, um die Produktivität und Effizienz in der Produktion zu verbessern.\n",
      "\n",
      "3. VERBESSERTE GROUND TRUTH EVALUIERUNG\n",
      "--------------------------------------------------\n",
      "Starte datengetriebene Evaluierung...\n",
      "- TF-IDF basierte Keyword-Extraktion\n",
      "- Problem-Muster aus echten Daten\n",
      "- Kombinierte Subsystem-Problem-Queries\n",
      "- Erweiterte Metriken (NDCG, Precision@K)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'run_improved_evaluation' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 53\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m- Erweiterte Metriken (NDCG, Precision@K)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     52\u001b[0m \u001b[38;5;66;03m# Führe verbesserte Evaluierung durch\u001b[39;00m\n\u001b[1;32m---> 53\u001b[0m improved_results \u001b[38;5;241m=\u001b[39m \u001b[43mrun_improved_evaluation\u001b[49m(analyzer)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m improved_results:\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mVERBESSERTE EVALUIERUNG ABGESCHLOSSEN\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'run_improved_evaluation' is not defined"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 1. SYSTEM INITIALISIERUNG\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n1. SYSTEM INITIALISIERUNG\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "CSV_FILE = \"Logbuch_Spritzgussanlage_NEU.csv\"\n",
    "\n",
    "analyzer = load_and_setup_analyzer(CSV_FILE)\n",
    "\n",
    "if analyzer is None:\n",
    "    print(\"FEHLER: System konnte nicht initialisiert werden!\")\n",
    "    print(\"Prüfen Sie die CSV-Datei und Dependencies.\")\n",
    "else:\n",
    "    print(\"SYSTEM ERFOLGREICH INITIALISIERT\")\n",
    "    print(f\"- Dateneinträge: {len(analyzer.df)}\")\n",
    "    print(f\"- Embedding-Modell: {analyzer.model_name}\")\n",
    "\n",
    "# =============================================================================\n",
    "# 2. DATENANALYSE FÜR GROUND TRUTH\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n2. DATENANALYSE FÜR VERBESSERTE GROUND TRUTH\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "print(\"Analyseergebnisse zur Produktionsproblematik:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Query: {analysis_results['query']}\")\n",
    "print(f\"Gefundene relevante Einträge: {analysis_results['result_count']} von {analysis_results['total_available']}\")\n",
    "print(f\"Durchschnittliche Relevanz: {analysis_results['average_relevance']:.3f}\")\n",
    "print(f\"Maximale Relevanz: {analysis_results['max_relevance']:.3f}\")\n",
    "print(f\"Suchqualität: {analysis_results['search_quality']}\\n\")\n",
    "\n",
    "print(\"LLM-Analyse (Zusammenfassung):\")\n",
    "print(analysis_results['llm_analysis'])\n",
    "\n",
    "# =============================================================================\n",
    "# 3. VERBESSERTE GROUND TRUTH EVALUIERUNG\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n3. VERBESSERTE GROUND TRUTH EVALUIERUNG\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "if analyzer is not None:\n",
    "    print(\"Starte datengetriebene Evaluierung...\")\n",
    "    print(\"- TF-IDF basierte Keyword-Extraktion\")\n",
    "    print(\"- Problem-Muster aus echten Daten\")\n",
    "    print(\"- Kombinierte Subsystem-Problem-Queries\")\n",
    "    print(\"- Erweiterte Metriken (NDCG, Precision@K)\")\n",
    "    \n",
    "    # Führe verbesserte Evaluierung durch\n",
    "    improved_results = run_improved_evaluation(analyzer)\n",
    "    \n",
    "    if \"error\" not in improved_results:\n",
    "        print(f\"\\nVERBESSERTE EVALUIERUNG ABGESCHLOSSEN\")\n",
    "        print(f\"=\" * 40)\n",
    "        \n",
    "        # Kernergebnisse\n",
    "        agg = improved_results[\"aggregate_metrics\"]\n",
    "        print(f\"HAUPTMETRIKEN:\")\n",
    "        print(f\"  Evaluierte Queries: {agg['queries_evaluated']}\")\n",
    "        print(f\"  Mean Precision@5:  {agg.get('mean_precision_at_5', 0):.3f}\")\n",
    "        print(f\"  Mean Precision@10: {agg.get('mean_precision', 0):.3f}\")\n",
    "        print(f\"  Mean Recall@10:    {agg.get('mean_recall', 0):.3f}\")\n",
    "        print(f\"  Mean F1-Score:     {agg.get('mean_f1', 0):.3f}\")\n",
    "        print(f\"  Mean NDCG@10:      {agg.get('mean_ndcg', 0):.3f}\")\n",
    "        \n",
    "        # Gesamtbewertung\n",
    "        if \"overall_evaluation\" in improved_results:\n",
    "            overall = improved_results[\"overall_evaluation\"]\n",
    "            print(f\"\\nGESAMTBEWERTUNG:\")\n",
    "            print(f\"  Score: {overall['overall_score']:.3f}/1.000\")\n",
    "            print(f\"  Bewertung: {overall['recommendation']}\")\n",
    "            print(f\"  Ground Truth Qualität: {overall['ground_truth_quality']}\")\n",
    "        \n",
    "        # Datenanalyse-Zusammenfassung\n",
    "        data_analysis = improved_results[\"data_analysis\"]\n",
    "        print(f\"\\nDATENANALYSE-ERGEBNISSE:\")\n",
    "        print(f\"  Analysierte Subsysteme: {data_analysis['subsystems_analyzed']}\")\n",
    "        print(f\"  Problem-Muster gefunden: {data_analysis['problem_patterns_found']}\")\n",
    "        print(f\"  Temporale Muster: {data_analysis['temporal_patterns']}\")\n",
    "        \n",
    "        # Vergleich verschiedener Precision@K Werte\n",
    "        print(f\"\\nPRECISION@K VERGLEICH:\")\n",
    "        for k in [5, 10, 15]:\n",
    "            precision_k = agg.get(f'mean_precision_at_{k}', 0)\n",
    "            if precision_k > 0:\n",
    "                print(f\"  Precision@{k}: {precision_k:.3f}\")\n",
    "    else:\n",
    "        print(f\"EVALUIERUNG FEHLGESCHLAGEN: {improved_results['error']}\")\n",
    "\n",
    "# =============================================================================\n",
    "# 4. VERGLEICH: ALTE VS NEUE GROUND TRUTH\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n4. VERGLEICH: REGEL-BASIERT VS DATENGETRIEBEN\")\n",
    "print(\"-\" * 55)\n",
    "\n",
    "if analyzer is not None and 'improved_results' in locals():\n",
    "    # Kurzer Vergleich mit alter Methode für Demonstration\n",
    "    from evaluation import LogbookEvaluator\n",
    "    \n",
    "    print(\"Führe zusätzlich regel-basierte Evaluierung durch (Vergleich)...\")\n",
    "    \n",
    "    old_evaluator = LogbookEvaluator(analyzer)\n",
    "    old_ground_truth = old_evaluator.create_rule_based_ground_truth()\n",
    "    \n",
    "    print(f\"\\nVERGLEICH DER METHODEN:\")\n",
    "    print(f\"  Regel-basierte GT:     {len(old_ground_truth)} Queries\")\n",
    "    print(f\"  Datengetriebene GT:    {improved_results['aggregate_metrics']['total_queries_created']} Queries\")\n",
    "    print(f\"  Evaluierbare Queries:  {improved_results['aggregate_metrics']['queries_evaluated']}\")\n",
    "    \n",
    "    # Qualitätsvergleich\n",
    "    if old_ground_truth:\n",
    "        print(f\"\\nQUALITÄTSVERGLEICH:\")\n",
    "        print(f\"  Regel-basiert:   Begrenzt auf vordefinierte Patterns\")\n",
    "        print(f\"  Datengetrieben:  Basiert auf echten {stats['total_entries']} Einträgen\")\n",
    "        print(f\"                   - TF-IDF Keywords aus realen Subsystemen\")\n",
    "        print(f\"                   - Problem-Muster aus Datenanalyse\")\n",
    "        print(f\"                   - Temporale und Lot-spezifische Patterns\")\n",
    "    \n",
    "    # Beispiel einer datengetriebenen Query\n",
    "    if 'improved_results' in locals() and improved_results.get('individual_results'):\n",
    "        example_query = list(improved_results['individual_results'].keys())[0]\n",
    "        example_metrics = improved_results['individual_results'][example_query]\n",
    "        \n",
    "        print(f\"\\nBEISPIEL DATENGETRIEBENE QUERY:\")\n",
    "        print(f\"  Query: '{example_query}'\")\n",
    "        print(f\"  Relevante Einträge: {example_metrics['relevant_count']}\")\n",
    "        print(f\"  Precision@10: {example_metrics['precision']:.3f}\")\n",
    "        print(f\"  Recall: {example_metrics['recall']:.3f}\")\n",
    "        print(f\"  NDCG: {example_metrics['ndcg']:.3f}\")\n",
    "\n",
    "# =============================================================================\n",
    "# 5. SEMANTISCHE SUCHE MIT ECHTEN DATENMUSTERN\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n5. SEMANTISCHE SUCHE MIT ECHTEN DATENMUSTERN\")\n",
    "print(\"-\" * 55)\n",
    "\n",
    "if analyzer is not None and 'improved_evaluator' in locals():\n",
    "    print(\"Demonstration mit Queries basierend auf echten Datenmustern:\")\n",
    "    \n",
    "    # Nutze die identifizierten Muster für Demonstration\n",
    "    demo_queries_real = []\n",
    "    \n",
    "    # Top Subsystem mit Top Problem kombinieren\n",
    "    if improved_evaluator.subsystem_keywords and improved_evaluator.problem_patterns:\n",
    "        top_subsystem = list(improved_evaluator.subsystem_keywords.keys())[0]\n",
    "        top_problem = list(improved_evaluator.problem_patterns.keys())[0]\n",
    "        demo_queries_real.append(f\"{top_problem} im {top_subsystem}\")\n",
    "    \n",
    "    # Weitere realistische Queries\n",
    "    if improved_evaluator.problem_patterns:\n",
    "        for problem in list(improved_evaluator.problem_patterns.keys())[:3]:\n",
    "            demo_queries_real.append(f\"Alle {problem} in der Anlage\")\n",
    "    \n",
    "    # Subsystem-spezifische Queries\n",
    "    if improved_evaluator.subsystem_keywords:\n",
    "        for subsystem in list(improved_evaluator.subsystem_keywords.keys())[:2]:\n",
    "            demo_queries_real.append(f\"Probleme im {subsystem}\")\n",
    "    \n",
    "    print(f\"\\nTeste {len(demo_queries_real)} echte datenbasierte Queries:\")\n",
    "    \n",
    "    for i, query in enumerate(demo_queries_real, 1):\n",
    "        print(f\"\\n{i}. Query: '{query}'\")\n",
    "        \n",
    "        indices, scores, count = analyzer.semantic_search(query)\n",
    "        \n",
    "        if count > 0:\n",
    "            avg_score = np.mean(scores)\n",
    "            high_relevance = sum(1 for s in scores if s >= 0.7)\n",
    "            \n",
    "            print(f\"   Ergebnisse: {count} gefunden\")\n",
    "            print(f\"   Qualität: Avg={avg_score:.3f}\")\n",
    "            print(f\"   Hochrelevant (≥0.7): {high_relevance}\")\n",
    "            \n",
    "            # Zeige bestes Ergebnis\n",
    "            if indices:\n",
    "                top_entry = analyzer.df.iloc[indices[0]]\n",
    "                subsystem = top_entry.get('Subsystem', 'N/A')\n",
    "                ereignis = str(top_entry.get('Ereignis & Massnahme', 'N/A'))[:60]\n",
    "                print(f\"   Bestes Match: [{subsystem}] {ereignis}...\")\n",
    "        else:\n",
    "            print(\"   Keine Ergebnisse gefunden\")\n",
    "\n",
    "# =============================================================================\n",
    "# 6. ERWEITERTE VISUALISIERUNGEN\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n6. ERWEITERTE VISUALISIERUNGEN\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "if analyzer is not None and 'improved_results' in locals():\n",
    "    # Erstelle erweiterte Visualisierung für verbesserte Metriken\n",
    "    try:\n",
    "        import matplotlib.pyplot as plt\n",
    "        \n",
    "        # Precision@K Vergleich\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "        \n",
    "        # Plot 1: Precision@K für verschiedene K-Werte\n",
    "        k_values = [5, 10, 15]\n",
    "        precisions = []\n",
    "        \n",
    "        agg = improved_results[\"aggregate_metrics\"]\n",
    "        for k in k_values:\n",
    "            precision_k = agg.get(f'mean_precision_at_{k}', 0)\n",
    "            precisions.append(precision_k)\n",
    "        \n",
    "        ax1.plot(k_values, precisions, 'bo-', linewidth=2, markersize=8)\n",
    "        ax1.set_xlabel('K (Top-K Ergebnisse)')\n",
    "        ax1.set_ylabel('Mean Precision@K')\n",
    "        ax1.set_title('Precision@K Verlauf')\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        ax1.set_ylim(0, 1)\n",
    "        \n",
    "        # Werte auf Plot anzeigen\n",
    "        for k, p in zip(k_values, precisions):\n",
    "            ax1.annotate(f'{p:.3f}', (k, p), textcoords=\"offset points\", xytext=(0,10), ha='center')\n",
    "        \n",
    "        # Plot 2: Metriken-Vergleich\n",
    "        metrics = ['Precision@10', 'Recall@10', 'F1-Score', 'NDCG@10']\n",
    "        values = [\n",
    "            agg.get('mean_precision', 0),\n",
    "            agg.get('mean_recall', 0), \n",
    "            agg.get('mean_f1', 0),\n",
    "            agg.get('mean_ndcg', 0)\n",
    "        ]\n",
    "        \n",
    "        colors = ['skyblue', 'lightgreen', 'lightcoral', 'gold']\n",
    "        bars = ax2.bar(metrics, values, color=colors, alpha=0.7)\n",
    "        ax2.set_ylabel('Score')\n",
    "        ax2.set_title('Erweiterte Evaluierungs-Metriken')\n",
    "        ax2.set_ylim(0, 1)\n",
    "        ax2.tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # Werte auf Balken\n",
    "        for bar, value in zip(bars, values):\n",
    "            height = bar.get_height()\n",
    "            ax2.text(bar.get_x() + bar.get_width()/2., height + 0.02,\n",
    "                    f'{value:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"Erweiterte Visualisierungen erstellt:\")\n",
    "        print(\"  - Precision@K Verlauf-Diagramm\") \n",
    "        print(\"  - Erweiterte Metriken-Übersicht\")\n",
    "        \n",
    "    except ImportError:\n",
    "        print(\"Matplotlib nicht verfügbar - Visualisierungen übersprungen\")\n",
    "\n",
    "# =============================================================================\n",
    "# 7. GROUND TRUTH QUALITÄTSANALYSE\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n7. GROUND TRUTH QUALITÄTSANALYSE\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "if analyzer is not None and 'improved_results' in locals():\n",
    "    print(\"ANALYSE DER GROUND TRUTH QUALITÄT:\")\n",
    "    \n",
    "    # Statistiken über Ground Truth\n",
    "    gt_stats = improved_results[\"ground_truth_stats\"]\n",
    "    gt_sizes = list(gt_stats.values())\n",
    "    \n",
    "    print(f\"\\nGROUND TRUTH STATISTIKEN:\")\n",
    "    print(f\"  Queries erstellt: {len(gt_stats)}\")\n",
    "    print(f\"  Durchschn. relevante Docs: {np.mean(gt_sizes):.1f}\")\n",
    "    print(f\"  Median relevante Docs: {np.median(gt_sizes):.1f}\")\n",
    "    print(f\"  Bereich: {min(gt_sizes)} - {max(gt_sizes)} relevante Docs\")\n",
    "    \n",
    "    # Verteilung der Ground Truth Größen\n",
    "    size_ranges = {\n",
    "        \"Klein (5-10)\": sum(1 for s in gt_sizes if 5 <= s <= 10),\n",
    "        \"Mittel (11-25)\": sum(1 for s in gt_sizes if 11 <= s <= 25),\n",
    "        \"Groß (26-50)\": sum(1 for s in gt_sizes if 26 <= s <= 50),\n",
    "        \"Sehr groß (>50)\": sum(1 for s in gt_sizes if s > 50)\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nVERTEILUNG DER GROUND TRUTH GRÖßEN:\")\n",
    "    for size_range, count in size_ranges.items():\n",
    "        percentage = (count / len(gt_sizes)) * 100\n",
    "        print(f\"  {size_range}: {count} Queries ({percentage:.1f}%)\")\n",
    "    \n",
    "    # Qualitätsindikatoren\n",
    "    individual_results = improved_results[\"individual_results\"]\n",
    "    high_precision_queries = sum(1 for r in individual_results.values() if r['precision'] >= 0.7)\n",
    "    high_recall_queries = sum(1 for r in individual_results.values() if r['recall'] >= 0.7)\n",
    "    high_f1_queries = sum(1 for r in individual_results.values() if r['f1'] >= 0.7)\n",
    "    \n",
    "    print(f\"\\nQUALITÄTSINDIKATOREN:\")\n",
    "    print(f\"  Queries mit hoher Precision (≥0.7): {high_precision_queries}/{len(individual_results)}\")\n",
    "    print(f\"  Queries mit hohem Recall (≥0.7): {high_recall_queries}/{len(individual_results)}\")\n",
    "    print(f\"  Queries mit hohem F1-Score (≥0.7): {high_f1_queries}/{len(individual_results)}\")\n",
    "\n",
    "# =============================================================================\n",
    "# 8. METHODISCHE VERBESSERUNGEN\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n8. METHODISCHE VERBESSERUNGEN\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "print(\"VERBESSERUNGEN GEGENÜBER REGEL-BASIERTER GROUND TRUTH:\")\n",
    "\n",
    "print(\"\\n1. DATENGETRIEBENER ANSATZ:\")\n",
    "print(\"   - TF-IDF Analyse extrahiert echte Subsystem-Keywords\")\n",
    "print(\"   - Problem-Muster aus 2500 echten Einträgen\")\n",
    "print(\"   - Automatische Identifikation häufiger Patterns\")\n",
    "print(\"   - Keine manuellen Keyword-Listen erforderlich\")\n",
    "\n",
    "print(\"\\n2. ERWEITERTE METRIKEN:\")\n",
    "print(\"   - NDCG@10 für rangbasierte Bewertung\")\n",
    "print(\"   - Precision@K für verschiedene K-Werte\")\n",
    "print(\"   - Detaillierte Fehleranalyse\")\n",
    "print(\"   - Statistische Signifikanz-Tests möglich\")\n",
    "\n",
    "print(\"\\n3. REALISTISCHE QUERIES:\")\n",
    "print(\"   - Kombinierte Subsystem-Problem-Queries\")\n",
    "print(\"   - Lot-spezifische Anfragen basierend auf echten Lot-Nummern\")\n",
    "print(\"   - Temporale Queries für aktive Zeiträume\")\n",
    "print(\"   - Berücksichtigung echter Datenverteilungen\")\n",
    "\n",
    "print(\"\\n4. OBJEKTIVE BEWERTUNG:\")\n",
    "print(\"   - Basiert auf quantitativen Datenmustern\")\n",
    "print(\"   - Reproduzierbare Ergebnisse\")\n",
    "print(\"   - Skalierbar auf größere Datensätze\")\n",
    "print(\"   - Wissenschaftlich fundierte Methodik\")\n",
    "\n",
    "# =============================================================================\n",
    "# 9. ABSCHLUSS UND ERKENNTNISSE\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n9. PROJEKTZUSAMMENFASSUNG - VERBESSERTE VERSION\")\n",
    "print(\"-\" * 55)\n",
    "\n",
    "if analyzer is not None and 'improved_results' in locals():\n",
    "    print(\"WICHTIGSTE VERBESSERUNGEN:\")\n",
    "    \n",
    "    agg = improved_results[\"aggregate_metrics\"]\n",
    "    \n",
    "    print(f\"\\n1. GROUND TRUTH QUALITÄT:\")\n",
    "    print(f\"   - {agg['total_queries_created']} datengetriebene Queries erstellt\")\n",
    "    print(f\"   - {agg['queries_evaluated']} evaluierbare High-Quality Queries\")\n",
    "    print(f\"   - Basiert auf echten Mustern aus {stats['total_entries']} Einträgen\")\n",
    "    \n",
    "    print(f\"\\n2. VERBESSERTE METRIKEN:\")\n",
    "    print(f\"   - Mean Precision@10: {agg.get('mean_precision', 0):.3f}\")\n",
    "    print(f\"   - Mean Recall@10: {agg.get('mean_recall', 0):.3f}\")\n",
    "    print(f\"   - Mean NDCG@10: {agg.get('mean_ndcg', 0):.3f}\")\n",
    "    print(f\"   - Precision@5: {agg.get('mean_precision_at_5', 0):.3f}\")\n",
    "    \n",
    "    if \"overall_evaluation\" in improved_results:\n",
    "        overall = improved_results[\"overall_evaluation\"]\n",
    "        print(f\"\\n3. GESAMTBEWERTUNG:\")\n",
    "        print(f\"   - Overall Score: {overall['overall_score']:.3f}/1.000\")\n",
    "        print(f\"   - Bewertung: {overall['recommendation']}\")\n",
    "        print(f\"   - Ground Truth: {overall['ground_truth_quality']}\")\n",
    "\n",
    "print(f\"\\n4. WISSENSCHAFTLICHER BEITRAG:\")\n",
    "print(f\"   - Datengetriebene Ground Truth Methodik für IR ohne Labels\")\n",
    "print(f\"   - TF-IDF basierte Domain-spezifische Keyword-Extraktion\")\n",
    "print(f\"   - Automatisierte Problem-Muster-Erkennung\")\n",
    "print(f\"   - Skalierbare Evaluierungs-Pipeline für Industriedaten\")\n",
    "\n",
    "print(f\"\\n5. ANWENDUNG AUF IHRE DATEN:\")\n",
    "print(f\"   - {len(improved_evaluator.subsystem_keywords)} echte Subsysteme analysiert\")\n",
    "print(f\"   - {len(improved_evaluator.problem_patterns)} Problem-Typen identifiziert\")\n",
    "print(f\"   - Temporale Muster in {len(improved_evaluator.temporal_patterns)} Zeiträumen\")\n",
    "print(f\"   - Methodik funktioniert mit Ihren 2500 echten Logbuch-Einträgen\")\n",
    "\n",
    "print(\"\\nVERFÜGBARE FUNKTIONEN:\")\n",
    "print(\"  • interactive_query_demo(analyzer) - Interaktive Suche\")\n",
    "print(\"  • run_improved_evaluation(analyzer) - Verbesserte Evaluierung\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"VERBESSERTE GROUND TRUTH EVALUIERUNG ABGESCHLOSSEN\")\n",
    "print(\"Datengetriebene Methodik mit echten Industriedaten validiert\")\n",
    "print(f\"{'='*60}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
